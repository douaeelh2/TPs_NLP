{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":131084,"sourceType":"datasetVersion","datasetId":2052}],"dockerImageVersionId":30664,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Lire les données","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport os\nfrom nltk.corpus import stopwords\nimport string\nfrom gensim.models import Word2Vec\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\n# Read dataset\ndf = pd.read_csv(\"/kaggle/input/movie-review/movie_review.csv\")\ndf.drop([\"fold_id\",\"cv_tag\",\"html_id\",\"sent_id\"], axis=1, inplace=True)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-20T14:11:28.559180Z","iopub.execute_input":"2024-03-20T14:11:28.559658Z","iopub.status.idle":"2024-03-20T14:11:28.766326Z","shell.execute_reply.started":"2024-03-20T14:11:28.559623Z","shell.execute_reply":"2024-03-20T14:11:28.764489Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"                                                text  tag\n0  films adapted from comic books have had plenty...  pos\n1  for starters , it was created by alan moore ( ...  pos\n2  to say moore and campbell thoroughly researche...  pos\n3  the book ( or \" graphic novel , \" if you will ...  pos\n4  in other words , don't dismiss this film becau...  pos","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>films adapted from comic books have had plenty...</td>\n      <td>pos</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>for starters , it was created by alan moore ( ...</td>\n      <td>pos</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>to say moore and campbell thoroughly researche...</td>\n      <td>pos</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>the book ( or \" graphic novel , \" if you will ...</td>\n      <td>pos</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>in other words , don't dismiss this film becau...</td>\n      <td>pos</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Pre-processing des données textuelles","metadata":{}},{"cell_type":"code","source":"STOPWORDS = set(stopwords.words('english'))\nPUNCT_TO_REMOVE = string.punctuation\n\n# Prétraitement des données textuelles\ndf['text'] = df['text'].str.lower()\ndf['text'] = df['text'].apply(lambda x: \" \".join([word for word in str(x).split() if word not in STOPWORDS]))\ndf['text'] = df['text'].apply(lambda text: text.translate(str.maketrans('', '', PUNCT_TO_REMOVE)))\n\n# Affichage des premières lignes du DataFrame\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-20T14:11:28.769004Z","iopub.execute_input":"2024-03-20T14:11:28.769461Z","iopub.status.idle":"2024-03-20T14:11:29.549427Z","shell.execute_reply.started":"2024-03-20T14:11:28.769425Z","shell.execute_reply":"2024-03-20T14:11:29.547775Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"                                                text  tag\n0  films adapted comic books plenty success  whet...  pos\n1  starters  created alan moore  eddie campbell  ...  pos\n2  say moore campbell thoroughly researched subje...  pos\n3  book   graphic novel    500 pages long include...  pos\n4                        words  dismiss film source   pos","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>films adapted comic books plenty success  whet...</td>\n      <td>pos</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>starters  created alan moore  eddie campbell  ...</td>\n      <td>pos</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>say moore campbell thoroughly researched subje...</td>\n      <td>pos</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>book   graphic novel    500 pages long include...</td>\n      <td>pos</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>words  dismiss film source</td>\n      <td>pos</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Entraînement du modèle Word2Vec","metadata":{}},{"cell_type":"code","source":"from gensim.models import Word2Vec\n\n# Tokenization des reviews\ntokenized_reviews = [nltk.word_tokenize(review) for review in df['text']]\n\n# Entraînement du modèle Word2Vec\nword2vec_model = Word2Vec(tokenized_reviews, vector_size=100, window=5, min_count=1, workers=4)","metadata":{"execution":{"iopub.status.busy":"2024-03-20T14:11:29.551301Z","iopub.execute_input":"2024-03-20T14:11:29.551714Z","iopub.status.idle":"2024-03-20T14:11:51.157422Z","shell.execute_reply.started":"2024-03-20T14:11:29.551680Z","shell.execute_reply":"2024-03-20T14:11:51.156377Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"# Vectorisation des reviews de movies","metadata":{}},{"cell_type":"code","source":"reviews_list = df['text'].apply(lambda x: x.split()).tolist()\n\ndef moyenne_Word2Vec(review, model, vector_size):\n    vectors = []\n    for token in review:\n        if token in model.wv:\n            vectors.append(model.wv[token])\n    if vectors:\n        return np.mean(vectors, axis=0)\n    else:\n        return np.zeros(vector_size)\n\nreview_vectors = [moyenne_Word2Vec(tokens, word2vec_model, vector_size=100) for tokens in reviews_list]","metadata":{"execution":{"iopub.status.busy":"2024-03-20T14:11:51.159954Z","iopub.execute_input":"2024-03-20T14:11:51.160341Z","iopub.status.idle":"2024-03-20T14:11:56.047239Z","shell.execute_reply.started":"2024-03-20T14:11:51.160310Z","shell.execute_reply":"2024-03-20T14:11:56.045455Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"# Division des données","metadata":{}},{"cell_type":"code","source":"X = review_vectors\ny = df['tag']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2024-03-20T14:11:56.050658Z","iopub.execute_input":"2024-03-20T14:11:56.051328Z","iopub.status.idle":"2024-03-20T14:11:56.103056Z","shell.execute_reply.started":"2024-03-20T14:11:56.051248Z","shell.execute_reply":"2024-03-20T14:11:56.101125Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"# Construction d'un classificateur","metadata":{}},{"cell_type":"code","source":"# Initialisation du modèle Logistic Regression\nmodel = LogisticRegression()\n\n# Entraînement du modèle\nmodel.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-03-20T14:11:56.104765Z","iopub.execute_input":"2024-03-20T14:11:56.105165Z","iopub.status.idle":"2024-03-20T14:11:57.850415Z","shell.execute_reply.started":"2024-03-20T14:11:56.105133Z","shell.execute_reply":"2024-03-20T14:11:57.848753Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"LogisticRegression()","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Évaluation du modèle","metadata":{}},{"cell_type":"code","source":"# Prédiction sur l'ensemble de test\ny_pred = model.predict(X_test)\n\n# Calcul des métriques d'évaluation\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='weighted')\nrecall = recall_score(y_test, y_pred, average='weighted')\nf1 = f1_score(y_test, y_pred, average='weighted')\n\n# Affichage des métriques d'évaluation\nprint(\"Accuracy:\", accuracy)\nprint(\"Precision:\", precision)\nprint(\"Recall:\", recall)\nprint(\"F1 Score:\", f1)","metadata":{"execution":{"iopub.status.busy":"2024-03-20T14:11:57.852993Z","iopub.execute_input":"2024-03-20T14:11:57.853889Z","iopub.status.idle":"2024-03-20T14:11:58.639785Z","shell.execute_reply.started":"2024-03-20T14:11:57.853829Z","shell.execute_reply":"2024-03-20T14:11:58.638254Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Accuracy: 0.5669035846724351\nPrecision: 0.5682093704083013\nRecall: 0.5669035846724351\nF1 Score: 0.561589659012406\n","output_type":"stream"}]}]}
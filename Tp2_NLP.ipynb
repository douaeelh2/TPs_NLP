{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1edc7eb9",
   "metadata": {},
   "source": [
    "# Chargement et prétraitement du texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cad2ce38",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (2083683508.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 10\u001b[1;36m\u001b[0m\n\u001b[1;33m    '''\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Chargement du texte\n",
    "text_path = \"C:/Users/ENVY/Downloads/text\"\n",
    "with open(text_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read().lower()  # Convertir le texte en minuscules pour éviter les différences de casse\n",
    "    \n",
    "'''\n",
    "Cette partie du code utilise une clause with pour ouvrir le fichier texte spécifié (text_path) en mode lecture (\"r\").\n",
    "Il utilise également l'encodage UTF-8 pour s'assurer que les caractères spéciaux peuvent être correctement interprétés.\n",
    "Ensuite, il lit le contenu du fichier à l'aide de la méthode read() et stocke le texte résultant dans la variable text.\n",
    "De plus, lower() est utilisé pour convertir le texte en minuscules, ce qui permet d'éviter les différences de casse \n",
    "lors du traitement ultérieur du texte.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818f556b",
   "metadata": {},
   "source": [
    "# 1. Extraire la représentation vectorielle d'un mot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b187b4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization du texte\n",
    "tokenized_text = [gensim.utils.simple_preprocess(word) for word in text.split()]\n",
    "\n",
    "# Entraîner le modèle Word2Vec\n",
    "model = Word2Vec(sentences=tokenized_text, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Exemple d'extraction de la représentation vectorielle d'un mot\n",
    "word_vector = model.wv['marrakech']\n",
    "print(\"Représentation vectorielle du mot 'marrakech':\", word_vector)\n",
    "\n",
    "'''\n",
    "Cette ligne crée un modèle Word2Vec en utilisant les paramètres suivants :\n",
    "\n",
    "sentences: Les phrases tokenisées à partir desquelles le modèle Word2Vec sera appris.\n",
    "vector_size: La taille des vecteurs de mots (représentations vectorielles) à apprendre. Dans cet exemple, les vecteurs seront de taille 100.\n",
    "window: La taille de la fenêtre contextuelle autour de chaque mot lors de l'apprentissage du modèle. Ici, elle est fixée à 5, ce qui signifie que le modèle prendra en compte les cinq mots précédents et les cinq mots suivants de chaque mot cible.\n",
    "min_count: Le nombre minimum d'occurrences d'un mot requis pour être inclus dans le modèle. Ici, elle est fixée à 1, ce qui signifie que tous les mots seront inclus, même s'ils ne sont présents qu'une seule fois dans le corpus.\n",
    "workers: Le nombre de threads à utiliser pour l'entraînement du modèle. Dans cet exemple, quatre threads seront utilisés.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fe623b",
   "metadata": {},
   "source": [
    "# 2. Calculer la similarité entre deux mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb4a5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_score = model.wv.similarity('morocco', 'country')\n",
    "print(\"Similarité entre 'morocco' et 'country':\", similarity_score)\n",
    "\n",
    "'''\n",
    "Dans le contexte de Gensim et de Word2Vec, wv fait référence à l'attribut \"Word Vectors\" de l'objet Word2Vec ou KeyedVectors.\n",
    "Cet attribut représente une collection de vecteurs de mots appris par le modèle Word2Vec.\n",
    "\n",
    "wv est l'attribut qui contient les vecteurs de mots appris par le modèle.\n",
    "similarity() est une méthode de l'objet WordVectors qui calcule la similarité cosinus entre deux mots.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0767d3d4",
   "metadata": {},
   "source": [
    "# 3. Extraire les mots contextuels (les plus similaires) pour un mot central donné"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92f0d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_words = model.wv.most_similar('morocco')\n",
    "print(\"Mots contextuels pour 'morocco':\", similar_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
